{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc62dafc",
   "metadata": {},
   "source": [
    "# Regridding CO:\n",
    "    \n",
    "This notebook will generate the results in the CO column of Table 1, with the exception of the last two rows, as well as Figure 8, the data needed to get the results in the first row of Table 5, and in Table 10. Make sure to replace any filepaths with the appropriate filepaths on your machine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a213d",
   "metadata": {},
   "source": [
    "First, we import all relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import netCDF4 as ntf\n",
    "from pyhdf.SD import SD, SDC\n",
    "import numpy as np\n",
    "import math\n",
    "from netCDF4 import Dataset \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import xesmf as xmf\n",
    "import xarray as xr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde3064",
   "metadata": {},
   "source": [
    "Next, we load in the raw dataset, where all the files that were downloaded are kept in one directory,\n",
    "and then extract the desired data into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_co = xr.open_mfdataset(\"/data0/rm3873/co_data/*.nc4\",concat_dim='TIMERANGE',combine='nested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42168f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_data = np.array(raw_co[\"CO_dof_A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a87c9",
   "metadata": {},
   "source": [
    "Here, we set up our parameters including info about the desired region, the size of the target grid, filepaths, latitude stride for the regridding, selected days, scale factor to apply to the data, and the key missing aggression parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9560ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_path = '/data0/rm3873/co_binary_regridded_v2.nc'\n",
    "land_mask_path = '/data0/zzheng/GEOS-Chem-grid/land_mask.nc'\n",
    "\n",
    "lat_st = 6\n",
    "lat_end = 36.25\n",
    "lat_siz = 0.25\n",
    "lon_st = 68.125\n",
    "lon_end = 97.8126\n",
    "lon_siz = 0.3125\n",
    "lat_start_idx = 0\n",
    "lat_end_idx = len(co_data[0])\n",
    "lon_start_idx = 0\n",
    "lon_end_idx = len(co_data[0][0])\n",
    "target_grid_lats = 121\n",
    "target_grid_lons = 96\n",
    "orig_grid_size = 0.25\n",
    "SCALE_FACTOR = 1\n",
    "day_start = 1\n",
    "day_end = 366\n",
    "\n",
    "ratio = int(target_grid_lats*target_grid_lons/(lat_end_idx*lon_end_idx))\n",
    "missing_aggression_over = 1\n",
    "missing_aggression_under = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d0941",
   "metadata": {},
   "source": [
    "Let's check the percent of missing data in the raw grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(~np.isnan(data))/(365*31*31)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafbdcb",
   "metadata": {},
   "source": [
    ".... and get the empty new grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded = np.full((day_end-day_start,target_grid_lats,target_grid_lons), np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577f5a0",
   "metadata": {},
   "source": [
    "Let's setup the regridded NetCDF file with our desired dimensions, we will fill in the 'co' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = Dataset(land_mask_path,mode='r',format='NETCDF4_CLASSIC')\n",
    "ncfile = Dataset(binary_path,mode='w',format='NETCDF4_CLASSIC') \n",
    "lat_dim = ncfile.createDimension('lat', target_grid_lats)     \n",
    "lon_dim = ncfile.createDimension('lon', target_grid_lons)\n",
    "time = ncfile.createDimension('time',day_end-day_start)\n",
    "\n",
    "lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "lat.units = 'degrees_north'\n",
    "lat.long_name = 'latitude'\n",
    "lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "lon.units = 'degrees_east'\n",
    "lon.long_name = 'longitude'\n",
    "time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "time.units = 'days of 2015'\n",
    "time.long_name = 'days_of_the_year'\n",
    "# Define a 3D variable to hold the data\n",
    "co = ncfile.createVariable('co',np.float64,('time','lat','lon')) # note: unlimited dimension is leftmost\n",
    "\n",
    "lat[:] = np.arange(lat_st,lat_end,lat_siz)\n",
    "lon[:] = np.arange(lon_st,lon_end,lon_siz)\n",
    "time[:] = np.arange(day_start,day_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e54d6b",
   "metadata": {},
   "source": [
    "Now for the core regridding process!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4392ba61",
   "metadata": {},
   "source": [
    "Let's make up a lookup table of sorts for the missing data in the current grid by means of a nearest-neighbors method in the grid: give each missing cell the value of its nearest non-missing cell (as deemed by L2 norm). Does not edit original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_raw_co = co_data\n",
    "for day in range(len(filled_raw_co)):\n",
    "    print(day)\n",
    "    for i in range(len(filled_raw_co[day])):\n",
    "        for j in range(len(filled_raw_co[day][i])):\n",
    "\n",
    "            if(not np.isnan(filled_raw_co[day][i][j])):\n",
    "                continue\n",
    "\n",
    "            min_dist = np.inf\n",
    "            for k in range(len(filled_raw_co[day])):\n",
    "                for l in range(len(filled_raw_co[day][k])):\n",
    "\n",
    "                    if(np.isnan(filled_raw_co[day][i][j])):\n",
    "                        continue\n",
    "\n",
    "                    cur_dist = np.sqrt((k-i)**2 + (l-j)**2)\n",
    "                    if(cur_dist < min_dist):\n",
    "                        filled_raw_co[day][i][j] = filled_raw_co[day][k][l]\n",
    "                        min_dist = cur_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082dd55a",
   "metadata": {},
   "source": [
    "What this algorithm can do is consider the cells in the target grid that will be mapped to from the original grid. For values that are oringinally missing, we use the nearest neighbor non-missing value as obtained from the last step, else we use the existent value. We use this value as the mean, and the variance be the ratio (which we set to be the ratio of the grid sizes) times the variance of the original data, and sample values from a normal distribution with these parameters to fill in the box that represents the extrapolated region. Because in the interpolation process used for the other regriddings, we would honor that concept by insert some missing values in both the case of a present value (to represent the number of missing values being under the threshold in an interpolation process) and in an original missing value (the number of present values is below the threshold). We using the missing_aggression under/over values to determine what fraction of the target box to randomly select to be missing.\n",
    "\n",
    "For the purposes of the result in the report, we simplify this process by simply considering a variance of 0, missing over thresholds of 1 and under thresholds of 0, aka, simply copying the original value into the target box by repeating it for every cell in the target box - even if it's missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(day_start,day_end):\n",
    "    print('Day: ' + str(day))\n",
    "    data = co_data[day-1]\n",
    "    var = ratio * np.nanvar(data)\n",
    "    \n",
    "    ct_lat = 0\n",
    "    lat_str = 4\n",
    "    i=lat_start_idx\n",
    "\n",
    "    while(i < lat_end_idx):\n",
    "        #Part III\n",
    "        if(i == 28):\n",
    "            lat_str = 3\n",
    "            \n",
    "        j = lon_start_idx\n",
    "        ct_lon = 0\n",
    "        lon_str = 3\n",
    "        \n",
    "        while(j < lon_end_idx):\n",
    "            if(j == 28):\n",
    "                lon_str = 4\n",
    "\n",
    "            #Part IV\n",
    "            cur_to_extrapolate = data[i][j]\n",
    "            \n",
    "            #Part V\n",
    "            to_add = None\n",
    "            cur_row = [m for m in range(ct_lat,ct_lat+lat_str)] \n",
    "            cur_col = [n for n in range(ct_lon,ct_lon+lon_str)]\n",
    "            cur_box_idx = np.ix_(cur_row,cur_col)\n",
    "            \n",
    "            if(np.isnan(cur_to_extrapolate)):\n",
    "                #to_add = np.random.normal(filled_raw_co[day-1][i][j],var,(lat_str,lon_str))\n",
    "                #num_miss = int(ratio*missing_aggression_over)\n",
    "                #mark_miss = np.random.choice(len(to_add)*len(to_add[0]),num_miss,replace=False)\n",
    "                #to_add = to_add.flatten()\n",
    "                #to_add[mark_miss] = np.nan\n",
    "                #to_add = to_add.reshape((lat_str,lon_str))\n",
    "                to_add = np.full((lat_str,lon_str), np.nan)\n",
    "            else:\n",
    "                #to_add = np.random.normal(cur_to_extrapolate,var,(lat_str,lon_str))\n",
    "                #num_miss = int(ratio*missing_aggression_under)\n",
    "                #mark_miss = np.random.choice(len(to_add)*len(to_add[0]),num_miss,replace=False)\n",
    "                #to_add = to_add.flatten()\n",
    "                #to_add[mark_miss] = np.nan\n",
    "                #to_add = to_add.reshape((lat_str,lon_str))\n",
    "                to_add = np.full((lat_str,lon_str), cur_to_extrapolate)\n",
    "            \n",
    "\n",
    "            #Part VII\n",
    "            regridded_co[day-1][cur_box_idx] = to_add\n",
    "            ct_lon = ct_lon + lon_str\n",
    "            j = j + 1\n",
    "\n",
    "\n",
    "        ct_lat = ct_lat + lat_str\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ddcaad",
   "metadata": {},
   "source": [
    "Let's read in the simulated data (already matched for the GEOS-Chem target grid), and copy them into a dictionary of the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_emission = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_emission.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_gas = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_gas_column.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_pm = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_surface_pm25_RH50.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_met = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_meteo.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_aod = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_aod.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_emission[\"EmisDST_Natural\"] = raw_emission[\"EmisDST1_Natural\"] + raw_emission[\"EmisDST2_Natural\"] + raw_emission[\"EmisDST3_Natural\"] + raw_emission[\"EmisDST4_Natural\"]\n",
    "feature_ml = [\n",
    "    {\"PM25\":[]},\n",
    "    {'CO_trop':[], 'SO2_trop':[], 'NO2_trop':[], 'CH2O_trop':[], 'NH3_trop':[]},\n",
    "     {'AOT_C':[], 'AOT_DUST_C':[]},\n",
    "    {'T2M':[], 'PBLH':[], 'U10M':[], 'V10M':[], 'PRECTOT':[], 'RH':[]},\n",
    "    {'EmisDST_Natural':[], \n",
    "                'EmisNO_Fert':[], 'EmisNO_Lightning':[], 'EmisNO_Ship':[], 'EmisNO_Soil':[]}]\n",
    "sets = [raw_pm,raw_gas,raw_aod,raw_met,raw_emission]\n",
    "\n",
    "for i in range(len(sets)):\n",
    "    for spec in feature_ml[i]:\n",
    "        print(spec)\n",
    "        cur_set = sets[i][spec]\n",
    "        \n",
    "        for entry in cur_set:\n",
    "            feature_ml[i][spec].append([])\n",
    "        for j in range(len(cur_set)):\n",
    "            print(j)\n",
    "            for k in range(len(cur_set[j])):\n",
    "                feature_ml[i][spec][j].append(cur_set[j][k])\n",
    "        feature_ml[i][spec] = np.array(feature_ml[i][spec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c2a8f",
   "metadata": {},
   "source": [
    "Now we can simply apply our CO regridded missing mask onto all these datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list = np.argwhere(np.isnan(regridded))\n",
    "missing_vals = [np.NaN] * len(missing_list)\n",
    "for j in range(len(sets)):\n",
    "    for spec in feature_ml[j]:\n",
    "        print(spec)\n",
    "        feature_ml[j][spec][tuple(np.transpose(missing_list))] = missing_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e35a86e",
   "metadata": {},
   "source": [
    "Finally, let's write all these datasets, now with the CO missing mask applied to them, to disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe06c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(feature_ml)):\n",
    "    for spec in feature_ml[i]:\n",
    "        fname = '/data0/rm3873/custom_regridded_no2_' + str(spec) + '.nc'\n",
    "        ncfile = Dataset(fname,mode='w',format='NETCDF4_CLASSIC') \n",
    "        lat_dim = ncfile.createDimension('lat', 121)     \n",
    "        lon_dim = ncfile.createDimension('lon', 96)\n",
    "        time = ncfile.createDimension('time',365)\n",
    "\n",
    "        lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "        lat.units = 'degrees_north'\n",
    "        lat.long_name = 'latitude'\n",
    "        lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "        lon.units = 'degrees_east'\n",
    "        lon.long_name = 'longitude'\n",
    "        time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "        time.units = 'days of 2015'\n",
    "        time.long_name = 'days_of_the_year'\n",
    "        # Define a 3D variable to hold the data\n",
    "        key_var = ncfile.createVariable(spec,np.float64,('time','lat','lon'))\n",
    "\n",
    "        lat[:] = np.arange(6,36.25,0.25)\n",
    "        lon[:] = np.arange(68.125,97.8126,0.3125)\n",
    "        time[:] = np.arange(1,366)\n",
    "        key_var[::] = feature_ml[i][spec]\n",
    "        ncfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
