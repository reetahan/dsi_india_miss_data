{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a25571",
   "metadata": {},
   "source": [
    "# Regridding NO2:\n",
    "    \n",
    "This notebook will generate the results in the NO2 column on Table 1, except the last two rows, as well as Figure 5, the data needed to get the results in the first row of Table 4, and Table 9. Make sure to replace any filepaths with the appropriate filepaths on your machine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b005b",
   "metadata": {},
   "source": [
    "First, we import all relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import netCDF4 as ntf\n",
    "from pyhdf.SD import SD, SDC\n",
    "import numpy as np\n",
    "import math\n",
    "from netCDF4 import Dataset \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import xesmf as xmf\n",
    "import xarray as xr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33603f25",
   "metadata": {},
   "source": [
    "Next, we load in the raw dataset, where all the files that were downloaded are kept in one directory, and then extract the desired data into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_no2 = xr.open_mfdataset(\"/data0/rm3873/daily_no2_v2/*.nc4\",concat_dim='TIMERANGE',combine='nested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058af066",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(raw_no2['ColumnAmountNO2Trop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96fea55",
   "metadata": {},
   "source": [
    "Here, we set up our parameters including info about the desired region, the size of the target grid, filepaths, latitude stride for the regridding, selected days, scale factor to apply to the data, and the key threshold to use for marking a target box as missing or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9560ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_path = '/data0/rm3873/no2_binary_regridded.nc'\n",
    "land_mask_path = '/data0/zzheng/GEOS-Chem-grid/land_mask.nc'\n",
    "TARGET_MISSING = -9999\n",
    "MISSING = np.nan\n",
    "WATER = -4999\n",
    "day_start = 1\n",
    "day_end = 366\n",
    "lat_st = 6\n",
    "lat_end = 36.25\n",
    "lat_siz = 0.25\n",
    "lon_st = 68.125\n",
    "lon_end = 97.8126\n",
    "lon_siz = 0.3125\n",
    "lat_start_idx = 0\n",
    "lat_end_idx = len(no2_data[0])\n",
    "lon_start_idx = 0\n",
    "lon_end_idx = len(no2_data[0][0])\n",
    "target_grid_lats = 121\n",
    "target_grid_lons = 96\n",
    "orig_grid_size = 0.25\n",
    "SCALE_FACTOR = 1\n",
    "missing_threshold = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d2035",
   "metadata": {},
   "source": [
    "Let's check the percent of missing data in the raw grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(~np.isnan(data))/(365*121*121)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b056666",
   "metadata": {},
   "source": [
    ".... and get the empty new grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded = np.full((day_end-day_start,target_grid_lats,target_grid_lons), np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87102f79",
   "metadata": {},
   "source": [
    "Let's setup the regridded NetCDF file with our desired dimensions, we will fill in the 'no2' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = Dataset(land_mask_path,mode='r',format='NETCDF4_CLASSIC')\n",
    "ncfile = Dataset(binary_path,mode='w',format='NETCDF4_CLASSIC') \n",
    "lat_dim = ncfile.createDimension('lat', target_grid_lats)     \n",
    "lon_dim = ncfile.createDimension('lon', target_grid_lons)\n",
    "time = ncfile.createDimension('time',day_end-day_start)\n",
    "\n",
    "lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "lat.units = 'degrees_north'\n",
    "lat.long_name = 'latitude'\n",
    "lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "lon.units = 'degrees_east'\n",
    "lon.long_name = 'longitude'\n",
    "time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "time.units = 'days of 2015'\n",
    "time.long_name = 'days_of_the_year'\n",
    "# Define a 3D variable to hold the data\n",
    "no2 = ncfile.createVariable('no2',np.float64,('time','lat','lon')) # note: unlimited dimension is leftmost\n",
    "\n",
    "lat[:] = np.arange(lat_st,lat_end,lat_siz)\n",
    "lon[:] = np.arange(lon_st,lon_end,lon_siz)\n",
    "time[:] = np.arange(day_start,day_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(day_start,day_end):\n",
    "    print('Day: ' + str(day))\n",
    "    ct_lat = 0\n",
    "    lat_str = 1\n",
    "    data = no2_data[day-1]\n",
    "    i=lat_start_idx\n",
    "\n",
    "    while(i < lat_end_idx):\n",
    "        #Part III\n",
    "        j = lon_start_idx\n",
    "        ct_lon = 0\n",
    "        lon_str = 2\n",
    "        while(j < lon_end_idx):\n",
    "            if(ct_lon == 25):\n",
    "                lon_str = 1\n",
    "            '''\n",
    "            if(land_mask[\"mask\"][ct_lat][ct_lon] == 0):\n",
    "                regridded_no2[day - 1][ct_lat][ct_lon] = WATER\n",
    "                ct_lon = ct_lon + 1\n",
    "                j = j + lon_str\n",
    "                continue\n",
    "            '''\n",
    "            #Part IV\n",
    "            #print('Bounding box: [' + str(i) + ',' + str(i+lat_str) + ' by ' + str(j) + ',' + str(j+lon_str) + '] for idx (' + str(ct_lat) + ',' + str(ct_lon) + ')')\n",
    "            cur_row = [m for m in range(i,i+lat_str)] \n",
    "            cur_col = [n for n in range(j,j+lon_str)]\n",
    "            cur_box_idx = np.ix_(cur_row,cur_col)\n",
    "            cur_box = data[cur_box_idx]\n",
    "            #Part V\n",
    "            total_ct = len(cur_box) * len(cur_box[0])\n",
    "            non_miss = []\n",
    "            for a in range(len(cur_box)):\n",
    "                for b in range(len(cur_box[a])):\n",
    "                    if(cur_box[a][b] != TARGET_MISSING):\n",
    "                        non_miss.append(cur_box[a][b]* SCALE_FACTOR)\n",
    "\n",
    "            #Part VI\n",
    "            cur_val = np.nan\n",
    "            if(len(non_miss) >= missing_threshold * total_ct):\n",
    "                non_miss = np.array(non_miss)\n",
    "                cur_val = np.average(non_miss)\n",
    "            \n",
    "\n",
    "            #Part VII\n",
    "            regridded[day - 1][ct_lat][ct_lon] = cur_val\n",
    "            ct_lon = ct_lon + 1\n",
    "            j = j + lon_str\n",
    "\n",
    "\n",
    "        ct_lat = ct_lat + 1\n",
    "        i = i + lat_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37465b",
   "metadata": {},
   "source": [
    "Let's read in the simulated data (already matched for the GEOS-Chem target grid), and copy them into a dictionary of the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_emission = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_emission.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_gas = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_gas_column.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_pm = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_surface_pm25_RH50.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_met = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_meteo.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_aod = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_aod.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_emission[\"EmisDST_Natural\"] = raw_emission[\"EmisDST1_Natural\"] + raw_emission[\"EmisDST2_Natural\"] + raw_emission[\"EmisDST3_Natural\"] + raw_emission[\"EmisDST4_Natural\"]\n",
    "feature_ml = [\n",
    "    {\"PM25\":[]},\n",
    "    {'CO_trop':[], 'SO2_trop':[], 'NO2_trop':[], 'CH2O_trop':[], 'NH3_trop':[]},\n",
    "     {'AOT_C':[], 'AOT_DUST_C':[]},\n",
    "    {'T2M':[], 'PBLH':[], 'U10M':[], 'V10M':[], 'PRECTOT':[], 'RH':[]},\n",
    "    {'EmisDST_Natural':[], \n",
    "                'EmisNO_Fert':[], 'EmisNO_Lightning':[], 'EmisNO_Ship':[], 'EmisNO_Soil':[]}]\n",
    "sets = [raw_pm,raw_gas,raw_aod,raw_met,raw_emission]\n",
    "\n",
    "for i in range(len(sets)):\n",
    "    for spec in feature_ml[i]:\n",
    "        print(spec)\n",
    "        cur_set = sets[i][spec]\n",
    "        \n",
    "        for entry in cur_set:\n",
    "            feature_ml[i][spec].append([])\n",
    "        for j in range(len(cur_set)):\n",
    "            print(j)\n",
    "            for k in range(len(cur_set[j])):\n",
    "                feature_ml[i][spec][j].append(cur_set[j][k])\n",
    "        feature_ml[i][spec] = np.array(feature_ml[i][spec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c90d9a",
   "metadata": {},
   "source": [
    "Now we can simply apply our NO2 regridded missing mask onto all these datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list = np.argwhere(np.isnan(regridded))\n",
    "missing_vals = [np.NaN] * len(missing_list)\n",
    "for j in range(len(sets)):\n",
    "    for spec in feature_ml[j]:\n",
    "        print(spec)\n",
    "        feature_ml[j][spec][tuple(np.transpose(missing_list))] = missing_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25404d1",
   "metadata": {},
   "source": [
    "Finally, let's write all these datasets, now with the NO2 missing mask applied to them, to disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe06c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(feature_ml)):\n",
    "    for spec in feature_ml[i]:\n",
    "        fname = '/data0/rm3873/custom_regridded_no2_' + str(spec) + '.nc'\n",
    "        ncfile = Dataset(fname,mode='w',format='NETCDF4_CLASSIC') \n",
    "        lat_dim = ncfile.createDimension('lat', 121)     \n",
    "        lon_dim = ncfile.createDimension('lon', 96)\n",
    "        time = ncfile.createDimension('time',365)\n",
    "\n",
    "        lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "        lat.units = 'degrees_north'\n",
    "        lat.long_name = 'latitude'\n",
    "        lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "        lon.units = 'degrees_east'\n",
    "        lon.long_name = 'longitude'\n",
    "        time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "        time.units = 'days of 2015'\n",
    "        time.long_name = 'days_of_the_year'\n",
    "        # Define a 3D variable to hold the data\n",
    "        key_var = ncfile.createVariable(spec,np.float64,('time','lat','lon'))\n",
    "\n",
    "        lat[:] = np.arange(6,36.25,0.25)\n",
    "        lon[:] = np.arange(68.125,97.8126,0.3125)\n",
    "        time[:] = np.arange(1,366)\n",
    "        key_var[::] = feature_ml[i][spec]\n",
    "        ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a39a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
