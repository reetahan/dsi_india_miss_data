{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b40d8f5",
   "metadata": {},
   "source": [
    "# Regridding NO2, CO via XESMF:\n",
    "    \n",
    "This notebook will generate the results in the last two rows of Table 1, as well as Figures 6, 7, 9 and 10, the data needed to get the results in the second rows of Tables 4 and 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4ed14",
   "metadata": {},
   "source": [
    "First, we import all relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import netCDF4 as ntf\n",
    "from pyhdf.SD import SD, SDC\n",
    "import numpy as np\n",
    "import math\n",
    "from netCDF4 import Dataset \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import xesmf as xmf\n",
    "import xarray as xr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e171e",
   "metadata": {},
   "source": [
    "Provide output filepaths as well as path to our land mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_path_patch_co = '/data0/rm3873/co_binary_patch_regridded_v0.nc'\n",
    "binary_path_bilinear_co = '/data0/rm3873/no2_binary_bilinear_regridded_v0.nc'\n",
    "binary_path_patch_no2 = '/data0/rm3873/co_binary_patch_regridded_v0.nc'\n",
    "binary_path_bilinear_no2 = '/data0/rm3873/no2_binary_bilinear_regridded_v0.nc'\n",
    "land_mask_path = '/data0/zzheng/GEOS-Chem-grid/land_mask.nc'\n",
    "target_grid_lats = 121\n",
    "target_grid_lons = 96\n",
    "day_start = 1\n",
    "day_end = 366\n",
    "year = 2015\n",
    "lat_st = 6\n",
    "lat_end = 36.25\n",
    "lat_siz = 0.25\n",
    "lon_st = 68.125\n",
    "lon_end = 97.8126\n",
    "lon_siz = 0.3125"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5cc40",
   "metadata": {},
   "source": [
    "Next, we load in the raw NO2 dataset, where all the files that were downloaded are kept in one directory, and then extract the desired data into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6691b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_data = xr.open_mfdataset(\"/data0/rm3873/daily_no2_data/*.nc4\",concat_dim='TIMERANGE',combine='nested')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fe0e0",
   "metadata": {},
   "source": [
    "Now, we can use the XESMF library for regridding NO2 under a bilinear scheme provided the desired boundaries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d848a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"lat\": ([\"lat\"], np.arange(6,36.25,.25)),\n",
    "        \"lon\": ([\"lon\"], np.arange(68,98,.3125)),\n",
    "    }\n",
    ")\n",
    "regridder = xmf.Regridder(no2_data, ds_out, \"bilinear\")\n",
    "no2_data = regridder(no2_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72393d6",
   "metadata": {},
   "source": [
    "Next, we load in the raw CO dataset, where all the files that were downloaded are kept in one directory, and then extract the desired data into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17557832",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_data = xr.open_mfdataset(\"/data0/rm3873/co_data/*.nc4\",concat_dim='TIMERANGE',combine='nested')\n",
    "co_data = co_data.rename({'Longitude': 'lon','Latitude': 'lat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318be7f",
   "metadata": {},
   "source": [
    "Now, we can use the XESMF library for regridding CO under a bilinear scheme provided the desired boundaries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"lat\": ([\"lat\"], np.arange(6,36.25,.25)),\n",
    "        \"lon\": ([\"lon\"], np.arange(68,98,.3125)),\n",
    "    }\n",
    ")\n",
    "regridder = xmf.Regridder(co_data, ds_out, \"bilinear\")\n",
    "co_data = regridder(co_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29254098",
   "metadata": {},
   "source": [
    "We extract the specific data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_grid = np.array(no2_data[\"ColumnAmountNO2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_grid = np.array(co_data[\"CO_dof_A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24020fd3",
   "metadata": {},
   "source": [
    "We repeat the above, but now it's to geneerate a regridding under the patch scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed565e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_data = xr.open_mfdataset(\"/data0/rm3873/co_data/*.nc4\",concat_dim='TIMERANGE',combine='nested')\n",
    "co_data = co_data.rename({'Longitude': 'lon','Latitude': 'lat'})\n",
    "no2_data = xr.open_mfdataset(\"/data0/rm3873/daily_no2_data/*.nc4\",concat_dim='TIMERANGE',combine='nested')\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"lat\": ([\"lat\"], np.arange(6,36.25,.25)),\n",
    "        \"lon\": ([\"lon\"], np.arange(68,98,.3125)),\n",
    "    }\n",
    ")\n",
    "regridder_co = xmf.Regridder(co_data, ds_out, \"patch\")\n",
    "co_data_patch = regridder_co(co_data)\n",
    "regridder_no2 = xmf.Regridder(no2_data, ds_out, \"patch\")\n",
    "no2_data_patch = regridder_no2(no2_data)\n",
    "patch_co_grid = np.array(co_data_patch[\"CO_dof_A\"])\n",
    "patch_no2_grid = np.array(no2_data_patch[\"ColumnAmountNO2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6437e1",
   "metadata": {},
   "source": [
    "Let's setup the regridded NetCDF file with our desired dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [binary_path_patch_co,binary_path_bilinear_co,binary_path_patch_no2,binary_path_bilinear_no2]:\n",
    "\n",
    "    land_mask = Dataset(land_mask_path,mode='r',format='NETCDF4_CLASSIC')\n",
    "    ncfile = Dataset(p,mode='w',format='NETCDF4_CLASSIC') \n",
    "    lat_dim = ncfile.createDimension('lat', target_grid_lats)     \n",
    "    lon_dim = ncfile.createDimension('lon', target_grid_lons)\n",
    "    time = ncfile.createDimension('time',day_end-day_start)\n",
    "\n",
    "    lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "    lat.units = 'degrees_north'\n",
    "    lat.long_name = 'latitude'\n",
    "    lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "    lon.units = 'degrees_east'\n",
    "    lon.long_name = 'longitude'\n",
    "    time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "    time.units = 'days of 2015'\n",
    "    time.long_name = 'days_of_the_year'\n",
    "    if(p in [binary_path_patch_co,binary_path_bilinear_co]):\n",
    "        # Define a 3D variable to hold the data\n",
    "        co = ncfile.createVariable('co',np.float64,('time','lat','lon')) # note: unlimited dimension is leftmost\n",
    "        if(p == binary_path_patch_co):\n",
    "            co[::] = patch_co_grid \n",
    "        else:\n",
    "            co[::] = co_grid\n",
    "    else:\n",
    "        no2 = ncfile.createVariable('no2',np.float64,('time','lat','lon')) # note: unlimited dimension is leftmost\n",
    "        if(p == binary_path_patch_no2):\n",
    "            no2[::] = patch_no2_grid \n",
    "        else:\n",
    "            no2[::] = no2_grid\n",
    "        \n",
    "\n",
    "    lat[:] = np.arange(lat_st,lat_end,lat_siz)\n",
    "    lon[:] = np.arange(lon_st,lon_end,lon_siz)\n",
    "    time[:] = np.arange(day_start,day_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b77db",
   "metadata": {},
   "source": [
    "Let's read in the simulated data (already matched for the GEOS-Chem target grid), and copy them into a dictionary of the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_emission = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_emission.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_gas = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_gas_column.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_pm = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_surface_pm25_RH50.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_met = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_meteo.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_aod = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_aod.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_emission[\"EmisDST_Natural\"] = raw_emission[\"EmisDST1_Natural\"] + raw_emission[\"EmisDST2_Natural\"] + raw_emission[\"EmisDST3_Natural\"] + raw_emission[\"EmisDST4_Natural\"]\n",
    "feature_ml = [\n",
    "    {\"PM25\":[]},\n",
    "    {'CO_trop':[], 'SO2_trop':[], 'NO2_trop':[], 'CH2O_trop':[], 'NH3_trop':[]},\n",
    "     {'AOT_C':[], 'AOT_DUST_C':[]},\n",
    "    {'T2M':[], 'PBLH':[], 'U10M':[], 'V10M':[], 'PRECTOT':[], 'RH':[]},\n",
    "    {'EmisDST_Natural':[], \n",
    "                'EmisNO_Fert':[], 'EmisNO_Lightning':[], 'EmisNO_Ship':[], 'EmisNO_Soil':[]}]\n",
    "sets = [raw_pm,raw_gas,raw_aod,raw_met,raw_emission]\n",
    "\n",
    "for i in range(len(sets)):\n",
    "    for spec in feature_ml[i]:\n",
    "        print(spec)\n",
    "        cur_set = sets[i][spec]\n",
    "        \n",
    "        for entry in cur_set:\n",
    "            feature_ml[i][spec].append([])\n",
    "        for j in range(len(cur_set)):\n",
    "            print(j)\n",
    "            for k in range(len(cur_set[j])):\n",
    "                feature_ml[i][spec][j].append(cur_set[j][k])\n",
    "        feature_ml[i][spec] = np.array(feature_ml[i][spec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e0a2b",
   "metadata": {},
   "source": [
    "Now we can simply apply our four regridded missing masks onto all these datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dict = {\"patch_regridded_co\":patch_co_grid,\"bilinear_regridded_co\":co_grid,\n",
    "             \"patch_regridded_no2\":patch_no2_grid,\"bilinear_regridded_co\":no2_grid}\n",
    "\n",
    "for grid_name in grid_dict:\n",
    "    missing_list = np.argwhere(np.isnan(grid_dict[grid_name]))\n",
    "    missing_vals = [np.NaN] * len(missing_list)\n",
    "    for j in range(len(sets)):\n",
    "        for spec in feature_ml[j]:\n",
    "            print(spec)\n",
    "            feature_ml[j][spec][tuple(np.transpose(missing_list))] = missing_vals\n",
    "\n",
    "    for i in range(len(feature_ml)):\n",
    "        for spec in feature_ml[i]:\n",
    "            fname = '/data0/rm3873/' + grid_name + '_' + str(spec) + '.nc'\n",
    "            ncfile = Dataset(fname,mode='w',format='NETCDF4_CLASSIC') \n",
    "            lat_dim = ncfile.createDimension('lat', 121)     \n",
    "            lon_dim = ncfile.createDimension('lon', 96)\n",
    "            time = ncfile.createDimension('time',365)\n",
    "\n",
    "            lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "            lat.units = 'degrees_north'\n",
    "            lat.long_name = 'latitude'\n",
    "            lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "            lon.units = 'degrees_east'\n",
    "            lon.long_name = 'longitude'\n",
    "            time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "            time.units = 'days of 2015'\n",
    "            time.long_name = 'days_of_the_year'\n",
    "            # Define a 3D variable to hold the data\n",
    "            key_var = ncfile.createVariable(spec,np.float64,('time','lat','lon'))\n",
    "\n",
    "            lat[:] = np.arange(6,36.25,0.25)\n",
    "            lon[:] = np.arange(68.125,97.8126,0.3125)\n",
    "            time[:] = np.arange(1,366)\n",
    "            key_var[::] = feature_ml[i][spec]\n",
    "            ncfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
