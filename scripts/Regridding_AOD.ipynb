{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767bd9dd",
   "metadata": {},
   "source": [
    "# Regridding AOD:\n",
    "    \n",
    "This notebook will generate the results in the AOD column on Table 1, as well as Figure 2, 3 and 4, the data needed to get the results in Tables 3 and 7.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f73f7",
   "metadata": {},
   "source": [
    "First, we import all relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import netCDF4 as ntf\n",
    "from pyhdf.SD import SD, SDC\n",
    "import numpy as np\n",
    "import math\n",
    "from netCDF4 import Dataset \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import xesmf as xmf\n",
    "import xarray as xr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702b11a",
   "metadata": {},
   "source": [
    "Here, as there was no simple tool provided with the data, we use a script to download the data, which we include as a function and its function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_aod_data():\n",
    "    s1 = \"https://portal.nccs.nasa.gov/datashare/maiac/DataRelease/CMG_0.05degree/AOT5km/2015/MAIACCMG.2015\"\n",
    "    s3 = \".hdf\"\n",
    "\n",
    "    for i in range(day_start,day_end):\n",
    "        outname = LOCAL + str(year) + \"_\" + str(i) + \".hdf\"\n",
    "\n",
    "        #Uncomment this section if you are running through your downloaded files and checking they are the right size.\n",
    "        '''\n",
    "        redownload_mode = True\n",
    "        size = os.path.getsize(outname)/1000000.0\n",
    "        print(str(size) + \" MB\")\n",
    "        if(size != expected_size_mb):\n",
    "            print(\"Re-downloading needed\")\n",
    "        else:\n",
    "            continue\n",
    "        '''\n",
    "        \n",
    "        progress_str = \"Downloading Day \" + str(i) + \" of \" + str(day_end - day_start)\n",
    "        if(redownload_mode):\n",
    "            progress_str = \"Re-downloading Day \" + str(i)\n",
    "\n",
    "        print(progress_str)      \n",
    "        s2 = str(i)\n",
    "        if(i < 10):\n",
    "            s2 = \"00\" + str(i)\n",
    "        if(i >= 10 and i < 100):\n",
    "            s2 = \"0\" + str(i)\n",
    "        link = s1+s2+s3\n",
    "\n",
    "        cmd = \"curl -o \" + outname + \" \" + link\n",
    "        os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data if not already downloaded\n",
    "download_aod_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e4646",
   "metadata": {},
   "source": [
    "Here, we set up our parameters including info about the desired region, the size of the target grid, filepaths, latitude stride for the regridding, selected days, scale factor to apply to the data, and the key threshold to use for marking a target box as missing or not. Regular mode considers averaging non-missing cells for target, binary mode simply reports 1s or 0s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9560ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = \"/data0/rm3873/regrid_data_005/\"\n",
    "day_start = 1\n",
    "day_end = 366\n",
    "year = 2015\n",
    "binary_path = '/data0/rm3873/binary_regridded_v2.nc'\n",
    "land_mask_path = '/data0/zzheng/GEOS-Chem-grid/land_mask.nc'\n",
    "TARGET_MISSING = -9999\n",
    "WATER = -4999\n",
    "lat_st = 6\n",
    "lat_end = 36.25\n",
    "lat_siz = 0.25\n",
    "lon_st = 68.125\n",
    "lon_end = 97.8126\n",
    "lon_siz = 0.3125\n",
    "target_grid_lats = 121\n",
    "target_grid_lons = 96\n",
    "orig_grid_size = 0.05\n",
    "SCALE_FACTOR = 0.01\n",
    "regular_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea541e86",
   "metadata": {},
   "source": [
    "We manually extract the desired dataset and limit it othe region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "MISSING = -28672\n",
    "for day in range(day_start, day_end):\n",
    "    fname = LOCAL + str(year) + \"_\" + str(day) + \".hdf\"\n",
    "    print(fname)\n",
    "    f = SD(fname, SDC.READ)\n",
    "    sel = f.select('AOT').get()\n",
    "    data.append(np.array(sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "data_ = []\n",
    "for day in range(365):\n",
    "    print(day)\n",
    "    cur = data[day]\n",
    "    cur_ = []\n",
    "    for i in range(1080,1680):\n",
    "        lons = []\n",
    "        for j in range(4960,5560):\n",
    "            lons.append(cur[i][j])\n",
    "        cur_.append(lons)\n",
    "    data_.append(cur_)\n",
    "data_ = np.array(data_)\n",
    "print(np.shape(data_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6582b1",
   "metadata": {},
   "source": [
    "Let's check the percent of missing data in the raw grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(data_ == MISSING)/(365*600*600)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1972ae0",
   "metadata": {},
   "source": [
    ".... and get the empty new grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded = np.full((day_end-day_start,target_grid_lats,target_grid_lons), TARGET_MISSING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa4aaa",
   "metadata": {},
   "source": [
    "General purpose diophantine equation solver, we determined the appropriate lat/long box stride lengths but could work on general solver to automate and observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_diophantine_solver():\n",
    "    # ax + by + cz + ... = orig_lat_size, x+y+z=new_lat_size\n",
    "    # dq + er + fs + ... = orig_lon_size, q+r+s=new_lon_size\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf2fc5",
   "metadata": {},
   "source": [
    "Let's setup the regridded NetCDF file with our desired dimensions, we will fill in the 'aot' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = Dataset(land_mask_path,mode='r',format='NETCDF4_CLASSIC')\n",
    "ncfile = Dataset(binary_path,mode='w',format='NETCDF4_CLASSIC') \n",
    "lat_dim = ncfile.createDimension('lat', target_grid_lats)     \n",
    "lon_dim = ncfile.createDimension('lon', target_grid_lons)\n",
    "time = ncfile.createDimension('time',day_end-day_start)\n",
    "\n",
    "lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "lat.units = 'degrees_north'\n",
    "lat.long_name = 'latitude'\n",
    "lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "lon.units = 'degrees_east'\n",
    "lon.long_name = 'longitude'\n",
    "time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "time.units = 'days of 2015'\n",
    "time.long_name = 'days_of_the_year'\n",
    "# Define a 3D variable to hold the data\n",
    "aot = ncfile.createVariable('aot',np.float64,('time','lat','lon')) # note: unlimited dimension is leftmost\n",
    "\n",
    "lat[:] = np.arange(lat_st,lat_end,lat_siz)\n",
    "lon[:] = np.arange(lon_st,lon_end,lon_siz)\n",
    "time[:] = np.arange(day_start,day_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448874a8",
   "metadata": {},
   "source": [
    "Here, we get the crux of the regridding. We map the box of cells in the source to a target cell, by checking if the number of present cells is above our threshold. If it is, we average the value of the present source cell to get the target cell, else we mark it as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_start_idx = int((90 - lat_end)/orig_grid_size) \n",
    "lat_end_idx = int((90 - lat_st)/orig_grid_size) \n",
    "lon_start_idx = int((180 + lon_st)/orig_grid_size)\n",
    "lon_end_idx = int((180 + lon_end)/orig_grid_size) \n",
    "\n",
    "for day in range(day_start,day_end):\n",
    "    \n",
    "    #Part I: Read\n",
    "    print('Day: ' + str(day))\n",
    "    fname = LOCAL + str(year) + \"_\" + str(day) + \".hdf\"\n",
    "    f = SD(fname, SDC.READ)\n",
    "    sel = f.select('AOT').get()\n",
    "    MISSING = -28672\n",
    "    data = np.full((3600,7200), MISSING)\n",
    "    for m in range(3600):\n",
    "        for n in range(7200):\n",
    "            data[m][n] = sel[m][n]\n",
    "    \n",
    "    #Part II\n",
    "    i=lat_start_idx\n",
    "    ct_lat = 0\n",
    "    lat_str = 5\n",
    "    threshold = 0.5\n",
    "\n",
    "\n",
    "    while(i < lat_end_idx):\n",
    "        #Part III\n",
    "        j = lon_start_idx\n",
    "        ct_lon = 0\n",
    "        lon_str = 6\n",
    "        while(j < lon_end_idx):\n",
    "            if(ct_lon == 90):\n",
    "                lon_str = 9\n",
    "\n",
    "            if(land_mask[\"mask\"][ct_lat][ct_lon] == 0):\n",
    "                regridded[day - 1][ct_lat][ct_lon] = WATER\n",
    "                ct_lon = ct_lon + 1\n",
    "                j = j + lon_str\n",
    "                continue\n",
    "\n",
    "            #Part IV\n",
    "            #print('Bounding box: [' + str(i) + ',' + str(i+lat_str) + ' by ' + str(j) + ',' + str(j+lon_str) + '] for idx (' + str(ct_lat) + ',' + str(ct_lon) + ')')\n",
    "            cur_row = [m for m in range(i,i+lat_str)] \n",
    "            cur_col = [n for n in range(j,j+lon_str)]\n",
    "            cur_box_idx = np.ix_(cur_row,cur_col)\n",
    "            cur_box = data[cur_box_idx]\n",
    "\n",
    "            #Part V\n",
    "            total_ct = len(cur_box) * len(cur_box[0])\n",
    "            non_miss = []\n",
    "            for a in range(len(cur_box)):\n",
    "                for b in range(len(cur_box[a])):\n",
    "                    if(cur_box[a][b] != MISSING):\n",
    "                        non_miss.append(cur_box[a][b]* SCALE_FACTOR)\n",
    "\n",
    "            #Part VI\n",
    "            cur_val = TARGET_MISSING\n",
    "            if(not regular_mode):\n",
    "                cur_val = 0\n",
    "            if(len(non_miss) >= threshold * total_ct):\n",
    "                non_miss = np.array(non_miss)\n",
    "                cur_val = np.average(non_miss)\n",
    "                if(not regular_mode):\n",
    "                    cur_val = 1\n",
    "\n",
    "            #Part VII\n",
    "            regridded[day - 1][ct_lat][ct_lon] = cur_val\n",
    "            ct_lon = ct_lon + 1\n",
    "            j = j + lon_str\n",
    "\n",
    "\n",
    "        ct_lat = ct_lat + 1\n",
    "        i = i + lat_str\n",
    "aot[::] = regridded\n",
    "ncfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e40912",
   "metadata": {},
   "source": [
    "Let's read in the simulated data (already matched for the GEOS-Chem target grid), and copy them into a dictionary of the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_emission = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_emission.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_gas = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_gas_column.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_pm = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_surface_pm25_RH50.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_met = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_meteo.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_aod = xr.open_dataset(\"/data0/rm3873/dsi_india/daily_aod.nc\").sel(lat=slice(6,36),lon=slice(68,98))\n",
    "raw_emission[\"EmisDST_Natural\"] = raw_emission[\"EmisDST1_Natural\"] + raw_emission[\"EmisDST2_Natural\"] + raw_emission[\"EmisDST3_Natural\"] + raw_emission[\"EmisDST4_Natural\"]\n",
    "feature_ml = [\n",
    "    {\"PM25\":[]},\n",
    "    {'CO_trop':[], 'SO2_trop':[], 'NO2_trop':[], 'CH2O_trop':[], 'NH3_trop':[]},\n",
    "     {'AOT_C':[], 'AOT_DUST_C':[]},\n",
    "    {'T2M':[], 'PBLH':[], 'U10M':[], 'V10M':[], 'PRECTOT':[], 'RH':[]},\n",
    "    {'EmisDST_Natural':[], \n",
    "                'EmisNO_Fert':[], 'EmisNO_Lightning':[], 'EmisNO_Ship':[], 'EmisNO_Soil':[]}]\n",
    "sets = [raw_pm,raw_gas,raw_aod,raw_met,raw_emission]\n",
    "\n",
    "for i in range(len(sets)):\n",
    "    for spec in feature_ml[i]:\n",
    "        print(spec)\n",
    "        cur_set = sets[i][spec]\n",
    "        \n",
    "        for entry in cur_set:\n",
    "            feature_ml[i][spec].append([])\n",
    "        for j in range(len(cur_set)):\n",
    "            print(j)\n",
    "            for k in range(len(cur_set[j])):\n",
    "                feature_ml[i][spec][j].append(cur_set[j][k])\n",
    "        feature_ml[i][spec] = np.array(feature_ml[i][spec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32d455",
   "metadata": {},
   "source": [
    "Now we can simply apply our AOD regridded missing mask onto all these datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list = np.argwhere(np.isnan(regridded))\n",
    "missing_vals = [np.NaN] * len(missing_list)\n",
    "for j in range(len(sets)):\n",
    "    for spec in feature_ml[j]:\n",
    "        print(spec)\n",
    "        feature_ml[j][spec][tuple(np.transpose(missing_list))] = missing_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03cbdf",
   "metadata": {},
   "source": [
    "Finally, let's write all these datasets, now with the AOD missing mask applied to them, to disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(feature_ml)):\n",
    "    for spec in feature_ml[i]:\n",
    "        fname = '/data0/rm3873/custom_regridded_aod_' + str(spec) + '.nc'\n",
    "        ncfile = Dataset(fname,mode='w',format='NETCDF4_CLASSIC') \n",
    "        lat_dim = ncfile.createDimension('lat', 121)     \n",
    "        lon_dim = ncfile.createDimension('lon', 96)\n",
    "        time = ncfile.createDimension('time',365)\n",
    "\n",
    "        lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "        lat.units = 'degrees_north'\n",
    "        lat.long_name = 'latitude'\n",
    "        lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "        lon.units = 'degrees_east'\n",
    "        lon.long_name = 'longitude'\n",
    "        time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "        time.units = 'days of 2015'\n",
    "        time.long_name = 'days_of_the_year'\n",
    "        # Define a 3D variable to hold the data\n",
    "        key_var = ncfile.createVariable(spec,np.float64,('time','lat','lon'))\n",
    "\n",
    "        lat[:] = np.arange(6,36.25,0.25)\n",
    "        lon[:] = np.arange(68.125,97.8126,0.3125)\n",
    "        time[:] = np.arange(1,366)\n",
    "        key_var[::] = feature_ml[i][spec]\n",
    "        ncfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
